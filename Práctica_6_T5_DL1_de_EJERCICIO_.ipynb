{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "colab": {
      "name": "Práctica 6 T5 DL1 de EJERCICIO_.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hosamfa3096/repositorio_IA3/blob/main/Pr%C3%A1ctica_6_T5_DL1_de_EJERCICIO_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lhPjB6w2qhy5"
      },
      "source": [
        "**El objetivo del ejercicio es:**\n",
        "\n",
        "- Optimizar arquitectura de la red\n",
        "\n",
        "- Partir training en training + validación usando como ejemplo lo que se hacía en el notebook de las caras (carpeta 03-caras)\n",
        "\n",
        "- Sacar heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrIBQZFhdEf_"
      },
      "source": [
        "COLAB = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21reopQOOK2g"
      },
      "source": [
        "if COLAB:\n",
        "    #%tensorflow_version 1.x\n",
        "    !pip install h5py==2.10.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J7jsb63yZMO"
      },
      "source": [
        "Si se desea ejecutar en local:\n",
        "\n",
        "- Descargar el dataset de training de: https://drive.google.com/file/d/1ChJn1h340ECm1uezE-oLr6TwCbeGglvQ\n",
        "\n",
        "- Y el de test de: https://drive.google.com/file/d/1STokCqelhLeiwlTa2YX-TM9SNCx74-an\n",
        "\n",
        "- Poner variable COLAB a False"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W68hFjybWa3P"
      },
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.models import Sequential, load_model, Model\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense, GlobalAveragePooling2D\n",
        "from keras.regularizers import l1, l2\n",
        "from keras import backend as K\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import regularizers\n",
        "from glob import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from IPython.display import SVG, display, clear_output\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GXDzz3bTLMV"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-8gOCujdP37"
      },
      "source": [
        "if COLAB:\n",
        "    from google_drive_downloader import GoogleDriveDownloader as gdd\n",
        "    gdd.download_file_from_google_drive(file_id='1ChJn1h340ECm1uezE-oLr6TwCbeGglvQ',\n",
        "                                        dest_path='./seg_train.zip', unzip=True)\n",
        "    gdd.download_file_from_google_drive(file_id='1STokCqelhLeiwlTa2YX-TM9SNCx74-an',\n",
        "                                        dest_path='./seg_test.zip', unzip=True)\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Tb3C1EgWz1r"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJlZPaYmW22d"
      },
      "source": [
        "!ls seg_train"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51wlCBp-zyOQ"
      },
      "source": [
        "!ls seg_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "walL9rvWW6Lf"
      },
      "source": [
        "!ls seg_train/buildings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ1xf6EVXdL-"
      },
      "source": [
        "ficheros = glob(\"./seg_train/forest/*\")\n",
        "ficheros[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Ck_4gkiezfz"
      },
      "source": [
        "imagen = load_img(ficheros[3])\n",
        "imagen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6OhpQXHsTAz"
      },
      "source": [
        "imagen.size"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# parto training en training + validación:\n",
        "\n",
        "clases = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"]\n",
        "\n",
        "rutas_trval  = []\n",
        "clases_trval = []\n",
        "for clase in clases:\n",
        "    rutas_aux  = glob(\"./seg_train/{}/*\".format(clase))\n",
        "    clases_aux = len(rutas_aux)*[clase]\n",
        "    print(rutas_aux[:3])\n",
        "    print(clases_aux[:3])\n",
        "\n",
        "    rutas_trval.extend(rutas_aux)\n",
        "    clases_trval.extend(clases_aux)\n"
      ],
      "metadata": {
        "id": "riu0Fd4uD-2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_trval = pd.DataFrame({\"ruta\":rutas_trval, \"clase\":clases_trval})\n",
        "df_trval"
      ],
      "metadata": {
        "id": "1dpEKXWJD-5l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df_train, df_val = train_test_split(df_trval, train_size=0.5, random_state=1, stratify=df_trval[\"clase\"])"
      ],
      "metadata": {
        "id": "HyH60k6YD-8q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train[\"clase\"].value_counts() / len(df_train) * 100"
      ],
      "metadata": {
        "id": "sZvy9Ck0D_AF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_val[\"clase\"].value_counts() / len(df_train) * 100"
      ],
      "metadata": {
        "id": "6x9m031PG1_v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrluBG4VWa3S"
      },
      "source": [
        "##train_data_dir = 'seg_train'\n",
        "##validation_data_dir = 'seg_test'\n",
        "test_data_dir = 'seg_test'\n",
        "\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c-u9ZVoRWANS"
      },
      "source": [
        "Para ver opciones:\n",
        "\n",
        "https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb3RiGQPYM1a"
      },
      "source": [
        "\n",
        "# data augmentation:\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1. / 255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode='mirror', # 'nearest',\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JEgFiD9Kap84"
      },
      "source": [
        "imagen_num = np.array([img_to_array(imagen)])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MUtIwZ_-Y3T0"
      },
      "source": [
        "plt.imshow(train_datagen.flow(imagen_num)[0][0])\n",
        "plt.axis(\"off\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx5NIFyWdSf_"
      },
      "source": [
        "# dimensiones a las que vamos a llevar las imágenes\n",
        "img_width, img_height = 150, 150\n",
        "\n",
        "normed_dims = (img_height, img_width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gwd_tQQGw2em"
      },
      "source": [
        "normed_dims"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxoRH0yK1ENu"
      },
      "source": [
        "# sparse_categorical_crossentropy\n",
        "\n",
        "#building: 0\n",
        "# 1,0,0,0,0,0\n",
        "\n",
        "# forest': 1\n",
        "# 0,1,0,0,0,0\n",
        "\n",
        "# glacier: 2\n",
        "# 0,0,1,0,0,0\n",
        "\n",
        "# mountain: 3\n",
        "# 0,0,0,1,0,0\n",
        "\n",
        "# sea: 4,\n",
        "# 0,0,0,0,1,0\n",
        "\n",
        "# street: 5\n",
        "# 0,0,0,0,0,1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_oPCg2IUWa3b"
      },
      "source": [
        "# Definir arquitectura del modelo:\n",
        "\n",
        "rate = 0.\n",
        "input_shape = normed_dims + (3,)\n",
        "\n",
        "#optimizer = \"sgd\"  # más fino, más lento\n",
        "#optimizer = \"adam\" # muy rápido, eso lo hace a veces inestable\n",
        "optimizer = \"rmsprop\" # bueno en general\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# rellenar\n",
        "\n",
        "\n",
        "model.compile(optimizer=optimizer, loss='sparse_categorical_crossentropy',\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FMhLfxCAWa3c"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju3YuClNWa3e"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "if COLAB:\n",
        "    display(SVG(model_to_dot(model, show_shapes=True,dpi=72).create(prog='dot', format='svg')))\n",
        "else:\n",
        "    display(SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg')))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87vJUmwv5XXg"
      },
      "source": [
        "def preprocess_input(x):\n",
        "    return x/255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WD-qj3yoyJDB"
      },
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    dtype='float32',\n",
        "    preprocessing_function = preprocess_input,\n",
        "    #rotation_range=40,\n",
        "    #width_shift_range=0.2,\n",
        "    #height_shift_range=0.2,\n",
        "    #fill_mode='nearest',\n",
        "    #shear_range=0.2,\n",
        "    #zoom_range=0.2,\n",
        "    horizontal_flip=True\n",
        "    )\n",
        "\n",
        "val_datagen  = ImageDataGenerator(dtype='float32',\n",
        "                                  preprocessing_function = preprocess_input)\n",
        "\n",
        "test_datagen = ImageDataGenerator(dtype='float32',\n",
        "                                  preprocessing_function = preprocess_input)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size"
      ],
      "metadata": {
        "id": "upzPKB7FI0p_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZlmhVC-bYM_1"
      },
      "source": [
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    df_train,\n",
        "    x_col = \"ruta\",\n",
        "    y_col = \"clase\",\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='sparse')\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    df_val,\n",
        "    x_col = \"ruta\",\n",
        "    y_col = \"clase\",\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    class_mode='sparse')\n",
        "\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False,\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u96-8fMjbIcx"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smKSN-oycTL6"
      },
      "source": [
        "number_train_samples = train_generator.n\n",
        "number_val_samples   = validation_generator.n\n",
        "number_test_samples  = test_generator.n\n",
        "\n",
        "number_train_samples, number_val_samples, number_test_samples"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WDSlstsKWa3i"
      },
      "source": [
        "from matplotlib.ticker import MaxNLocator\n",
        "\n",
        "def grafica_entrenamiento(tr_acc, val_acc, tr_loss, val_loss, best_i,\n",
        "                          figsize=(10,4)):\n",
        "    plt.figure(figsize=figsize)\n",
        "    ax = plt.subplot(1,2,1)\n",
        "    plt.plot(1+np.arange(len(tr_acc)),  100*np.array(tr_acc))\n",
        "    plt.plot(1+np.arange(len(val_acc)), 100*np.array(val_acc))\n",
        "    plt.plot(1+best_i, 100*val_acc[best_i], 'or')\n",
        "    plt.title('tasa de acierto del modelo (%)', fontsize=18)\n",
        "    plt.ylabel('tasa de acierto (%)', fontsize=18)\n",
        "    plt.xlabel('época', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "\n",
        "    plt.subplot(1,2,2)\n",
        "    plt.plot(1+np.arange(len(tr_acc)), np.array(tr_loss))\n",
        "    plt.plot(1+np.arange(len(val_acc)), np.array(val_loss))\n",
        "    plt.plot(1+best_i, val_loss[best_i], 'or')\n",
        "    plt.title('loss del modelo', fontsize=18)\n",
        "    plt.ylabel('loss', fontsize=18)\n",
        "    plt.xlabel('época', fontsize=18)\n",
        "    plt.legend(['entrenamiento', 'validación'], loc='upper left')\n",
        "    ax.xaxis.set_major_locator(MaxNLocator(integer=True))\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvUaztU0Wa3l"
      },
      "source": [
        "acum_tr_acc = []\n",
        "acum_val_acc = []\n",
        "best_val_acc = -1000\n",
        "acum_tr_loss  = []\n",
        "acum_val_loss = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nqta4BkIWa3n"
      },
      "source": [
        "epochs = 50\n",
        "\n",
        "modelpath=\"best_model.h5\"\n",
        "\n",
        "checkpoint = ModelCheckpoint(modelpath, monitor='val_accuracy', verbose=1,\n",
        "                              save_best_only=True,\n",
        "                              mode='max') # graba sólo los que mejoran en validación\n",
        "callbacks_list = [checkpoint]\n",
        "for e in range(epochs):\n",
        "    history = model.fit_generator(generator = train_generator, \n",
        "                                  steps_per_epoch=number_train_samples // batch_size,\n",
        "                                  epochs=1,\n",
        "                                  callbacks=callbacks_list,\n",
        "                                  verbose=1,\n",
        "                                  shuffle = True,\n",
        "                                  validation_data=validation_generator,\n",
        "                                  validation_steps=number_val_samples // batch_size\n",
        "                                  )\n",
        "    \n",
        "    if history.history['val_accuracy'][-1] > best_val_acc:\n",
        "        print(\"Validation accuracy improved from\",\n",
        "            best_val_acc, 'to', history.history['val_accuracy'])\n",
        "        print(\"saving weights\")\n",
        "        best_val_acc = history.history['val_accuracy'][-1]\n",
        "    \n",
        "    acum_tr_acc.append(history.history['accuracy'][0])\n",
        "    acum_val_acc.append(history.history['val_accuracy'][0])\n",
        "    acum_tr_loss.append(history.history['loss'][0])\n",
        "    acum_val_loss.append(history.history['val_loss'][0])\n",
        "    \n",
        "    if len(acum_tr_acc) > 1:\n",
        "        clear_output()\n",
        "        best_i = np.argmax(acum_val_acc)\n",
        "        grafica_entrenamiento(acum_tr_acc, acum_val_acc, acum_tr_loss, acum_val_loss, best_i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CqZiUFDMzUut"
      },
      "source": [
        "!ls -la"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYGAMNyndDoM"
      },
      "source": [
        "model = load_model(modelpath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNI07vcLWa3q"
      },
      "source": [
        "## **Resultados obtenidos**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-g2AYJqWa3t"
      },
      "source": [
        "scores_tr = model.evaluate(train_generator)\n",
        "print('Train loss    :', scores_tr[0])\n",
        "print('Train accuracy:', scores_tr[1])\n",
        "print()\n",
        "\n",
        "scores_val = model.evaluate(validation_generator)\n",
        "print('Val loss    :', scores_val[0])\n",
        "print('Val accuracy:', scores_val[1])\n",
        "print()\n",
        "\n",
        "scores_te = model.evaluate(test_generator)\n",
        "print('Test loss     :', scores_te[0])\n",
        "print('Test accuracy :', scores_te[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "maD61ufgWa3w"
      },
      "source": [
        "y_real = test_generator.classes\n",
        "y_pred_proba = model.predict_generator(test_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GsQqq2ewvuyN"
      },
      "source": [
        "y_real[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3x0PZ_OvwzJ"
      },
      "source": [
        "y_pred_proba[:5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IUy_VwwNvieF"
      },
      "source": [
        "test_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U3ynd71Lv3QX"
      },
      "source": [
        "num2class = {test_generator.class_indices[x]:x  for x in test_generator.class_indices.keys()}\n",
        "num2class"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x28VTWUvWa3y"
      },
      "source": [
        "for clase in range(6):\n",
        "    nombre_clase = num2class[clase]\n",
        "\n",
        "    fpr, tpr, thresholds = roc_curve(y_real==clase, y_pred_proba[:,clase])\n",
        "    fig, ax1 = plt.subplots(1,1)\n",
        "    ax1.plot(fpr, tpr, 'r-.', label = 'CNN (%2.2f)' % auc(fpr, tpr))\n",
        "    ax1.set_xlabel('False Positive Rate')\n",
        "    ax1.set_ylabel('True Positive Rate')\n",
        "    ax1.plot(fpr, fpr, 'b-', label = 'Random Guess')\n",
        "    ax1.set_title(nombre_clase)\n",
        "    ax1.legend()\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ASQl208vrWGX"
      },
      "source": [
        "## **Visualización de ejemplos de test**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zt9vxEizseSE"
      },
      "source": [
        "test_datagen2 = ImageDataGenerator(dtype='float32')\n",
        "\n",
        "test_generator2 = test_datagen2.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=test_generator.n,\n",
        "    shuffle=False,\n",
        "    class_mode='sparse')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dq_wZK3DseUW"
      },
      "source": [
        "test_generator2.reset()\n",
        "X_te, y_te = test_generator2.next()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQRqjEUucGM"
      },
      "source": [
        "test_generator2.class_indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sPfpH_ytQkK"
      },
      "source": [
        "y_te"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def show_probs(probs):\n",
        "    cadena = \"\"\n",
        "    for i in range(len(num2class)):\n",
        "        cadena = cadena + \"{}: {}% \".format(num2class[i], int(100*probs[i]))\n",
        "    print(cadena)"
      ],
      "metadata": {
        "id": "gFopdClWvS8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62rtQ4ERrric"
      },
      "source": [
        "ind_te1 = 1020 # 145\n",
        "\n",
        "image = X_te[ind_te1].copy()\n",
        "\n",
        "print(\"Clase real:\", num2class[y_te[ind_te1]])\n",
        "plt.imshow(image/255, cmap='jet')\n",
        "plt.axis(\"off\")\n",
        "p = model.predict(preprocess_input(np.array([image])))[0]\n",
        "\n",
        "show_probs(p)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FD-AVoQZ7g5Q"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VP5G-sGWx4qT"
      },
      "source": [
        "# Para descargar el modelo a local:\n",
        "\n",
        "#from google.colab import files\n",
        "#files.download('./best_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Heatmaps"
      ],
      "metadata": {
        "id": "wUoBpKLvT8MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_dir"
      ],
      "metadata": {
        "id": "JkoXRA8_UK2r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# primero cargo a memoria los ejemplos de test:\n",
        "\n",
        "test_datagen2 = ImageDataGenerator(dtype='float32',\n",
        "                                   preprocessing_function = preprocess_input)\n",
        "\n",
        "test_generator2 = test_datagen.flow_from_directory(\n",
        "    test_data_dir,\n",
        "    target_size=normed_dims,\n",
        "    batch_size=test_generator.n, # todas las imágenes del directorio test\n",
        "    shuffle=False,\n",
        "    class_mode='sparse') # binary: 0/1. Sparse: entero a partir de 0. Categorical: one hot"
      ],
      "metadata": {
        "id": "piqpxrfZT9rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_generator2.reset()\n",
        "X_te, y_te = test_generator2.next()"
      ],
      "metadata": {
        "id": "aOtcMphqUX0r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_te.shape"
      ],
      "metadata": {
        "id": "6O0hPnOYUZWc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WQoyV4pvA-Zf"
      },
      "source": [
        "import tensorflow as tf\n",
        "import cv2\n",
        "\n",
        "def find_ind_last_conv2D(model):\n",
        "    ind_last_conv2D_layer = None\n",
        "    for i,x in enumerate(model.layers):\n",
        "        if x.__class__.__name__ == \"Conv2D\":\n",
        "            ind_last_conv2D_layer = i\n",
        "    return ind_last_conv2D_layer\n",
        "\n",
        "\n",
        "def show_heatmap(model, im):\n",
        "    imag = np.expand_dims(im, axis=0) # de 1 imagen pasamos a 1 conjunto de 1 imagen\n",
        "    probs = model.predict(imag)[0]\n",
        "        \n",
        "    # The is the output feature map of the last convolutional layer\n",
        "    last_conv_layer = model.layers[find_ind_last_conv2D(model)]\n",
        "    \n",
        "    # This is the gradient of the \"benign\" class with regard to\n",
        "    # the output feature map of last convolutional layer\n",
        "    with tf.GradientTape() as tape:\n",
        "        aux = model.output\n",
        "        #aux = model.layers[-2].output # salida de la última capa densa antes de softmax\n",
        "\n",
        "        iterate = tf.keras.models.Model([model.inputs], [aux, last_conv_layer.output])\n",
        "        model_out, last_conv_layer = iterate(imag)\n",
        "        class_out = model_out[:, np.argmax(model_out[0])]\n",
        "        grads = tape.gradient(class_out, last_conv_layer)\n",
        "\n",
        "        # mean intensity of the gradient over a specific feature map channel:\n",
        "        pooled_grads = K.mean(grads, axis=(0, 1, 2))\n",
        "    \n",
        "    heatmap = tf.reduce_mean(tf.multiply(pooled_grads, last_conv_layer), axis=-1)    \n",
        "    heatmap = np.maximum(heatmap, 0) # se quitan los negativos (se ponen a 0)\n",
        "    heatmap /= np.max(heatmap) # se normaliza entre 0 y 1\n",
        "    heatmap = heatmap[0] # pasamos de 1 conjunto de 1 heatmap a 1 heatmap\n",
        "    \n",
        "    # We use cv2 to load the original image\n",
        "    #img = cv2.imread(img_path)\n",
        "    img = imag[0]\n",
        "    \n",
        "    img = np.zeros((im.shape[0],im.shape[1],3))\n",
        "#    print(im.shape, imag.shape)\n",
        "    for i in range(3):\n",
        "        img[:,:,i] = imag[0,:,:,0]\n",
        "\n",
        "    \n",
        "    # We resize the heatmap to have the same size as the original image\n",
        "    heatmap = cv2.resize(heatmap, (img.shape[1], img.shape[0]))\n",
        "    \n",
        "    # We convert the heatmap to RGB\n",
        "    heatmap = np.uint8(255 * heatmap)\n",
        "    \n",
        "    # We apply the heatmap to the original image\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET) / 255\n",
        "    #heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_BONE) / 255\n",
        "    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_HOT) / 255\n",
        "    \n",
        "    \n",
        "    # 0.4 here is a heatmap intensity factor\n",
        "    superimposed_img = heatmap * 0.5 + 0.5*im\n",
        "    #print(heatmap.min(), heatmap.max(), heatmap.mean(), heatmap.std())\n",
        "    #print(img.min(), img.max(), img.mean(), img.std())\n",
        "    #print(superimposed_img.min(),  superimposed_img.max(),\n",
        "    #      superimposed_img.mean(), superimposed_img.std())\n",
        "    \n",
        "    plt.figure(figsize=(15,5))\n",
        "    plt.subplot(1,3,1)\n",
        "    plt.imshow(im, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,3,2)\n",
        "    plt.imshow(heatmap, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.subplot(1,3,3)\n",
        "    plt.imshow(superimposed_img, vmin=0, vmax=1); plt.xticks([]); plt.yticks([])\n",
        "    plt.show()\n",
        "    show_probs(probs)\n",
        "    #print(np.shape(imag))\n",
        "    ##prob = 100*model.predict(imag)[0][class_indices[\"female\"]]\n",
        "    ##print(\"Probabilidad clase female: {:2.1f}%\".format(prob))\n",
        "    ##prob = 100*model.predict(imag)[0][class_indices[\"male\"]]\n",
        "    ##print(\"Probabilidad clase male  : {:2.1f}%\".format(prob))\n",
        "    ##print(\"\\n\\n\")\n",
        "    return heatmap, superimposed_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "r8F1GRfKVBRt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ind = 1041 # visualizamos 10 ejemplos de test a partir de este (en test hay 2002 ejemplos)\n",
        "ind = 200\n",
        "\n",
        "for i in range(ind, ind+10):\n",
        "    show_heatmap(model, X_te[i])\n",
        "    print(\"Real class:\", num2class[y_te[i]])\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "DeARWi2OTNwd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num2class"
      ],
      "metadata": {
        "id": "ym-Y6O4TxzfX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mayores equivocaciones en una clase"
      ],
      "metadata": {
        "id": "pk2lxDaMx6zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_proba = model.predict(X_te)"
      ],
      "metadata": {
        "id": "TKvW3JR80KmF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clase = 0\n",
        "\n",
        "inds = np.where(y_te == clase)[0]\n",
        "\n",
        "inds_mayores_errores = sorted(inds, key=lambda ind:y_pred_proba[ind, clase])\n",
        "n_errores = 10\n",
        "\n",
        "for ind in inds_mayores_errores[:n_errores]:\n",
        "    show_heatmap(model, X_te[ind])\n",
        "    print(\"Real class:\", num2class[y_te[ind]])\n",
        "    print(\"\\n\\n\")"
      ],
      "metadata": {
        "id": "mzpq-UUSUzPb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "1Z-a_p0FTN0n"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}